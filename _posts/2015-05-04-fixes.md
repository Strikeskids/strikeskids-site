---
title: Fix the FFT
author: strikeskids
---

I set out to figure out what was wrong with my decoding algorithm at 8am last Sunday. The FFT worked by itself with the size 16 test cases that I had been trying out, so I figured that it must be something in the higher levels of the algorithm. However, the autocorrelation also worked with size 16 test cases.

I eventually decided to read through the data that was being sent through to the autocorrelation, because what else could it possibly be. That was when I found that the data being passed into the autocorrelation was not the same data as the data being input into the decode method. That was wrong. It turns out that what was happening was I was overwriting data with the input before I ever read it.

    CELLS   0   1   2   3   4   5   6   7

    WRITE 1 0   4   2   6   1   5   3   7
    WRITE 2 8  12  10  14   9  13  11  15

    READ 1  6   7   8   9  10  11  12  13

Notice that the read call to cells 4 and 6 happen after the the second write. That meant the data from the first section was getting polluted by the second section. I had originally implemented the method this way because I thought there was not a good way to implement it with the pipeline. After a bunch of playing around with permutations, I managed to find a relatively simple way to perform the revbin permutation on the samples while they were in the pipeline. I will omit the details at this time because they are rather complicated to explain and much easier to show.

For some reason, it still wasn't working after fixing this part. Then, when examining each of the decoding steps, I decided on a whim to make sure that they all had the correct values as determined by Mathematica. That was when I hit the jackpot. Apparently, the FFT was not actually working with large cases. It worked fine with the small 16 sample cases that I had been testing, but it didn't work with the size 256 case that I needed for the decode.

I set up a very robust (difficult to compute and asymmetric) FFT that I could easily scale from size 16 to 256 and set out to figure out the issue. It worked fine with 16 samples, as I had found before, but with 32 samples it broke again. I altered my Javascript FFT to print out which samples should be getting mixed together for the FFT in order to check that all of the permutations were working properly. The permutations in the FFT were the only thing that could go wrong, as I had already fixed the twiddle factors. I had also set up the multiplication module to scream at me if there were multiplication overflows.

With the new setup, I found that all of the permutations up until the final permutation worked identically to the Javascript FFT worked. I knew that the Javascript FFT was correct because I had already used it to generate the epicycles animation. That meant that the only thing wrong was the final permutation. To my chagrin, I realized that I was using a transition permutation for the final step instead of a revbin permutation. The FFT was supposed to take inputs in the revbin ordering and output them in the revbin ordering. The permutations left everything almost in revbin, except the pairs of samples were in forward ordering (instead of revbin). Luckily, I had already written a revbin permutation for the decode input, so I could just use that as the final step. This was the issue that was preventing it from working all along. Suddenly, the whole decode method worked!

![decode simulation]({{ site.url }}/resources/decodesimul.png)

Above, we can see the little spikes in `next` and `next_out` that show when the the next section of input and output, respectively, will start. The output is a single bit corresponding to the input of 128 samples.
